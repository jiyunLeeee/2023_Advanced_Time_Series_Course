# -*- coding: utf-8 -*-
"""시뮬레이션 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KbSJWNnKxHUgYqflb5EE7mYt4T6VDXld
"""

from google.colab import drive
drive.mount('/content/drive/')

# 데이터 파일의 한글과 그래프에서 한글을 깨짐 없이 보기 위해 아래 코드를 실행한 후 런타임을 재시작한다.
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

import pandas as pd
import numpy as np
import random

import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
import pickle

import time
import re

# TS test & plot
import statsmodels.graphics.tsaplots as sgt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.seasonal import seasonal_decompose
import statsmodels.api as sm

# Model
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error , mean_absolute_percentage_error
from statsmodels.tsa.statespace.sarimax import SARIMAX

# LSTM
#! pip install scikit-optimize
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

import torch.optim as optim
from hyperopt import hp, fmin, tpe

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Warnings
import warnings
warnings.filterwarnings('ignore')

# palette 설정
sns.set_palette("pastel")

# 평가지표
def evaluate_metrics(test, pred):
    rmse = mean_squared_error(test, pred)
    mae = mean_absolute_error(test, pred)
    mape = mean_absolute_percentage_error(test, pred)

    return {'RMSE': rmse,
            'MAE': mae,
            'MAPE': mape}

"""#### 1. SARIMAX(2,0,1)(0,1,1)7
- 정규분포 오차를 갖는 SARIMAX 모형에서 자료를 생성한 후, SARIMAX 모형, LSTM과 Hybrid SARIMAX-LSTM 성능 비교
"""

simulated_data_list = []

# Order & Parameter
order = (2, 0, 1)  ; seasonal_order = (0, 1, 1, 7)
mu = 10  ;  phi1 = 0.9  ;  phi2 = -0.6  ;  theta1 = 0.5  ;  Theta1 = 0.3  ;  gamma1 = -100
params = np.array([mu, phi1, phi2, theta1, Theta1, gamma1])

for _ in tqdm(range(1000), desc = "Simulating Data"):
    # Data
    endogenous_series = pd.Series(np.random.randn(365))
    exogenous_series = pd.Series(np.random.choice([0, 1], size = 365, p = [1 - 0.1, 0.1]))

    # Model & Simulation
    model = SARIMAX(endog = endogenous_series,
                    exog = exogenous_series,
                    order = order,
                    initialization='approximate_diffuse',
                    seasonal_order = seasonal_order,
                    params = params
    )

    errors = np.random.normal(loc = 0, scale = 20, size = 365)
    result = model.fit()
    simulated_data = result.simulate(nsimulations = 365, anchor = 'start', innovations = errors)
    simulated_data_list.append(simulated_data)

def plot_simulated(data, num_simulations):
    data_num = 1
    for i, simulated_data in enumerate(tqdm(data[:num_simulations], desc = "Plotting Data")):
        decomposition = seasonal_decompose(simulated_data, model = 'additive', period = 7)

        plt.figure(figsize=(15, 12))

        plt.subplot(6, 1, 1)
        plt.plot(decomposition.observed)
        plt.title(f'Simulated data ({data_num})')

        #plt.subplot(6, 1, 2)
        #plt.plot(decomposition.trend)
        #plt.title(f'Trend ({data_num})')

        #plt.subplot(6, 1, 3)
        #plt.plot(decomposition.seasonal)
        #plt.title(f'Seasonal Component ({data_num})')

        #plt.subplot(6, 1, 4)
        #plt.plot(decomposition.resid)
        #plt.title(f'Residual Component ({data_num})')

        #plt.subplot(6, 2, 5)
        #ax = plt.gca()
        #plot_acf(simulated_data, lags=40, ax=ax)
        #plt.title(f'ACF ({data_num})')

        #plt.subplot(6, 2, 6)
        #ax = plt.gca()
        #plot_pacf(simulated_data, lags=40, ax=ax)
        #plt.title(f'PACF ({data_num})')

        data_num += 1

        #plt.tight_layout()
        plt.show()

plot_simulated(simulated_data_results, 5)

"""##### 1) SARIMAX"""

from sklearn.model_selection import train_test_split

def fit_predict_evaluate_sarimax(simulations, order, seasonal_order):
    evaluation_results = [] ; predicted_results = [] ; test_set =[]

    for simulated_data in tqdm(simulations, desc = "Fitting and Forecasting"):
        train_data, test_data = train_test_split(simulated_data, test_size = 14/365, shuffle = False)

        exogenous_series = pd.Series(np.random.choice([0, 1], size = len(simulated_data), p = [1 - 0.1, 0.1]),
                                    index = simulated_data.index)

        model = SARIMAX(train_data,
                        exog = exogenous_series[:len(train_data)],
                        order = order,
                        seasonal_order = seasonal_order,
                        initialization = 'approximate_diffuse',
                        enforce_stationarity = False)
        result = model.fit()

        forecast = result.get_forecast(steps = len(test_data), exog = exogenous_series[len(train_data):])

        predicted_values = forecast.predicted_mean
        predicted_results.append(predicted_values)

        evaluation_result = evaluate_metrics(test_data, predicted_values)
        evaluation_results.append(evaluation_result)

        test_set.append(test_data)

    return evaluation_results , predicted_results, test_set

order = (2, 0, 1) ; seasonal_order = (0, 1, 1, 7)

evaluation_results , predicted_results, test_set = fit_predict_evaluate_sarimax(simulated_data_results, order, seasonal_order)

evaluation_results = []

for i in range(200):
    evaluation_results.append(evaluate_metrics(test_sar[i], pred_sar[i]))

mean_rmse = np.mean([result['RMSE'] for result in evaluation_results])
mean_mae = np.mean([result['MAE'] for result in evaluation_results])
mean_mape = np.mean([result['MAPE'] for result in evaluation_results])

mean_rmse = np.array(mean_rmse).reshape(-1, 1)
mean_mae = np.array(mean_mae).reshape(-1, 1)
mean_mape = np.array(mean_mape).reshape(-1, 1)

# Create a MinMaxScaler instance
scaler = MinMaxScaler()

# Fit and transform the data
mean_rmse_scaled = scaler.fit_transform(mean_rmse)
mean_mae_scaled = scaler.fit_transform(mean_mae)
mean_mape_scaled = scaler.fit_transform(mean_mape)

print("Mean RMSE:", mean_rmse)
print("Mean MAE:", mean_mae)
print("Mean MAPE:", mean_mape)

for i in range(2):
    plt.figure(figsize=(11, 10))

    # Plot actual values
    plt.plot(test_sar[i].values, label='Actual', linestyle='-', marker='o')

    # Plot predicted values on the same graph
    plt.plot(pred_sar[i].values, label='Predicted', linestyle='--', marker='x')

    plt.legend()
    plt.title(f'SARIMAX Actual vs. Predicted (simul-{i+1}th)')
    plt.show()

"""##### 2) LSTM"""

# MinMax Scaling
data = np.array(simulated_data_results)

scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

def train_test_split(data, time_step):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:i+time_step])
        y.append(data[i+time_step])
    return X, y

class LSTM(nn.Module):
    def __init__(self, input_size, output_size, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate, num_layers):
        super(LSTM, self).__init__()

        self.num_fc_layers = int(num_fc_layers)
        self.num_lstm_node = int(num_lstm_node)
        self.num_fc_node = int(num_fc_node)
        self.dropout_rate = dropout_rate
        self.input_size = int(input_size)
        self.output_size = int(output_size)
        self.num_layers = int(num_layers)

        self.lstm = nn.LSTM(input_size=self.input_size,
                            hidden_size=self.num_lstm_node,
                            num_layers=self.num_layers,
                            batch_first=True)
        self.dropout = nn.Dropout(p=dropout_rate)

        self.fc_layers = nn.ModuleList([])

        if self.num_fc_layers >= 1:
            self.fc_layers.append(nn.Linear(self.num_lstm_node, self.num_fc_node))
            if self.num_fc_layers > 1:
                for _ in range(self.num_fc_layers - 1):
                    self.fc_layers.append(nn.Linear(self.num_fc_node, self.num_fc_node))

            self.output_layer = nn.Linear(self.num_fc_node, self.output_size)
        else:
            self.output_layer = nn.Linear(self.num_lstm_node, self.output_size)
        self.tanh = nn.Tanh()

    def forward(self, x):
        h_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        c_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        out, (h_n, c_n) = self.lstm(x, (h_n, c_n))
        out = out[:, -1, :]

        out = self.tanh(out)
        out = self.dropout(out)

        for layer in self.fc_layers:
            out = layer(out)
            out = self.tanh(out)
            out = self.dropout(out)

        out = self.output_layer(out)

        return out

def train_evaluate_lstm(learning_rate, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate):
    model = LSTM(input_size = X_train.shape[2],
                 output_size = 1,
                 num_fc_layers = num_fc_layers,
                 num_lstm_node = num_lstm_node,
                 num_fc_node = num_fc_node,
                 dropout_rate = dropout_rate,
                 num_layers = 2)
    model.to(device)  # GPU

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr = learning_rate)

    num_epochs = 1000
    early_stopping_patience = 50
    best_valid_loss = float('inf')
    no_improvement = 0

    for epoch in range(num_epochs):
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # GPU
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        model.eval()
        valid_loss = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                valid_loss += criterion(outputs, labels).item()
        valid_loss /= len(test_loader)

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            no_improvement = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            no_improvement += 1

        if no_improvement >= early_stopping_patience:
            print(f'Early stopping after {epoch + 1} epochs with no improvement.')
            break

    return best_valid_loss

space = {
    'learning_rate': hp.uniform('learning_rate', 0.001, 0.01),
    'num_fc_layers': hp.quniform('num_fc_layers', 0, 2, 1),
    'num_lstm_node': hp.quniform('num_lstm_node', 16, 128, 16),
    'num_fc_node': hp.quniform('num_fc_node', 16, 128, 16),
    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)
}

def objective(params):
    try:
        test_loss = train_evaluate_lstm(params['learning_rate'],
                                        params['num_fc_layers'],
                                        params['num_lstm_node'],
                                        params['num_fc_node'],
                                        params['dropout_rate'])
        return test_loss

    except Exception as e:
        print("Error occurred:", e)
        return float('inf')

evaluation_metrics = [] ; y_pred_list = [] ; y_test_list = []

def prepare_data(data):
    X, y = train_test_split(data.reshape(-1, 1), time_step = 14)
    X_train, y_train = X[:337], y[:337]
    X_test, y_test = X[337:], y[337:]

    # To tensor
    X_train = torch.Tensor(X_train)
    X_test = torch.Tensor(X_test)

    y_train = torch.Tensor(y_train)
    y_test = torch.Tensor(y_test)

    # Reshape tensor
    X_train = X_train.permute(0, 2, 1)
    X_test = X_test.permute(0, 2, 1)

    # To data loader
    train_data = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)

    test_data = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_data, batch_size=32)

    return X_train, X_test, y_train, y_test, train_loader, test_loader

def final_evaluate_model(data):
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(data)
    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50)
    print("Best Hyperparameters:", best)

    best_model = LSTM(input_size=X_train.shape[2],
                      output_size=1,
                      num_fc_layers=best['num_fc_layers'],
                      num_lstm_node=best['num_lstm_node'],
                      num_fc_node=best['num_fc_node'],
                      dropout_rate=best['dropout_rate'],
                      num_layers=2)


    with torch.no_grad():
        y_pred = best_model(X_test)
        y_pred = y_pred.numpy()
        evaluation = evaluate_metrics(y_test, y_pred)

    return evaluation, y_pred


for i in tqdm(range(0, 20)):
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(data_scaled[i])
    evaluation, y_pred = final_evaluate_model(data_scaled[i])
    evaluation_metrics.append(evaluation)
    y_pred_list.append(y_pred)
    y_test_list.append(y_test)

    if (i + 1) % 20 == 0:
      with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm_1/y_pred_list_{i + 1}.pkl', 'wb') as f:
          pickle.dump(y_pred_list, f)
          print(f'y_pred_list_{i + 1}.pkl saved.')
      with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm_1/evaluation_metrics_{i + 1}.pkl', 'wb') as f:
          pickle.dump(evaluation_metrics, f)
          print(f'evaluation_metrics_{i + 1}.pkl saved.')
      with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm_1/y_test_list_{i + 1}.pkl', 'wb') as f:
          pickle.dump(y_test_list, f)
          print(f'y_test_list_{i + 1}.pkl saved.')

mean_rmse = np.mean([evaluation['RMSE'] for evaluation in evaluation_metrics])
mean_mae = np.mean([evaluation['MAE'] for evaluation in evaluation_metrics])
mean_mape = np.mean([evaluation['MAPE'] for evaluation in evaluation_metrics])

print("Mean RMSE:", mean_rmse)
print("Mean MAE:", mean_mae)
print("Mean MAPE:", mean_mape)

"""### LSTM - with exog"""

data = []
for i in range(len(simulated_data_results)):
  exog = pd.Series(np.random.choice([0, 1], size=365, p=[0.9, 0.1]))
  combined_data = np.column_stack((simulated_data_results[i], exog))
  data.append(combined_data)

data = np.array(data)

input_list_fin_scaled = []

for i in range(200):
    concatenated_data = pd.concat([pd.DataFrame(data[i]), pd.DataFrame(simulated_data_results[i])], axis=1)

    concatenated_data.columns = concatenated_data.columns.astype(str)

    scaler = MinMaxScaler()
    concatenated_data_scaled = pd.DataFrame(scaler.fit_transform(concatenated_data), columns=concatenated_data.columns)

    input_list_fin_i_scaled = concatenated_data_scaled.iloc[:, :len(data[i])]
    input_list_fin_scaled.append(input_list_fin_i_scaled)

features_train = [sublist.drop('y',axis=1) for sublist in input_list_fin_scaled]
labels_train = [sublist['y'] for sublist in input_list_fin_scaled]

features_train = np.array(features_train)
labels_train = np.array(labels_train)

def train_test_split(x_data, y_data , time_step = 14):
    X, y = [], []
    for i in range(len(x_data) - time_step):
        X.append(x_data[i:i+time_step])
        y.append(y_data[i+time_step])
    return X, y

# LSTM
class LSTM(nn.Module):
    def __init__(self, input_size, output_size, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate, num_layers):
        super(LSTM, self).__init__()

        self.num_fc_layers = int(num_fc_layers)
        self.num_lstm_node = int(num_lstm_node)
        self.num_fc_node = int(num_fc_node)
        self.dropout_rate = dropout_rate
        self.input_size = int(input_size)
        self.output_size = int(output_size)
        self.num_layers = int(num_layers)

        self.lstm = nn.LSTM(input_size=self.input_size,
                            hidden_size=self.num_lstm_node,
                            num_layers=self.num_layers,
                            batch_first=True)
        self.dropout = nn.Dropout(p=dropout_rate)

        self.fc_layers = nn.ModuleList([])

        if self.num_fc_layers >= 1:
            self.fc_layers.append(nn.Linear(self.num_lstm_node, self.num_fc_node))
            if self.num_fc_layers > 1:
                for _ in range(self.num_fc_layers - 1):
                    self.fc_layers.append(nn.Linear(self.num_fc_node, self.num_fc_node))

            self.output_layer = nn.Linear(self.num_fc_node, self.output_size)
        else:
            self.output_layer = nn.Linear(self.num_lstm_node, self.output_size)
        self.tanh = nn.Tanh()

    def forward(self, x):
        h_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        c_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        out, (h_n, c_n) = self.lstm(x, (h_n, c_n))
        out = out[:, -1, :]

        out = self.tanh(out)
        out = self.dropout(out)

        for layer in self.fc_layers:
            out = layer(out)
            out = self.tanh(out)
            out = self.dropout(out)

        out = self.output_layer(out)

        return out


def train_evaluate_lstm(learning_rate, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate):
    model = LSTM(input_size = X_train.shape[2],
                 output_size = 1,
                 num_fc_layers = num_fc_layers,
                 num_lstm_node = num_lstm_node,
                 num_fc_node = num_fc_node,
                 dropout_rate = dropout_rate,
                 num_layers = 2)
    model.to(device)  # GPU

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr = learning_rate)

    num_epochs = 1000
    early_stopping_patience = 50
    best_valid_loss = float('inf')
    no_improvement = 0

    for epoch in range(num_epochs):
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # GPU
            optimizer.zero_grad()
            outputs = model(inputs)
            labels = labels.view(labels.size(0), -1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        model.eval()
        valid_loss = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                labels = labels.view(labels.size(0), -1)
                valid_loss += criterion(outputs, labels).item()
        valid_loss /= len(test_loader)

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            no_improvement = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            no_improvement += 1

        if no_improvement >= early_stopping_patience:
            print(f'Early stopping after {epoch + 1} epochs with no improvement.')
            break

    return best_valid_loss


space = {
    'learning_rate': hp.uniform('learning_rate', 0.001, 0.01),
    'num_fc_layers': hp.quniform('num_fc_layers', 0, 2, 1),
    'num_lstm_node': hp.quniform('num_lstm_node', 16, 128, 16),
    'num_fc_node': hp.quniform('num_fc_node', 16, 128, 16),
    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)
}

def objective(params):
    try:
        test_loss = train_evaluate_lstm(learning_rate = params['learning_rate'],
                                        num_fc_layers = params['num_fc_layers'],
                                        num_lstm_node = params['num_lstm_node'],
                                        num_fc_node = params['num_fc_node'],
                                        dropout_rate = params['dropout_rate'])

        return test_loss

    except Exception as e:
        print("Error occurred:", e)
        return float('inf')


evaluation_metrics = []
y_pred_list = []
y_test_list = []

def prepare_data(data, data_y):
    X, y = train_test_split(data, data_y, time_step=14)

    X_train, y_train = X[:337], y[:337]
    X_test, y_test = X[337:], y[337:]

    # To tensor
    X_train = torch.Tensor(X_train)
    X_test = torch.Tensor(X_test)

    y_train = torch.Tensor(y_train).view(-1, 1)
    y_test = torch.Tensor(y_test).view(-1, 1)

    # Reshape tensor
    X_train = X_train.permute(0, 2, 1)
    X_test = X_test.permute(0, 2, 1)

    # To data loader
    train_data = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)

    test_data = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_data, batch_size=32)

    return X_train, X_test, y_train, y_test, train_loader, test_loader

def final_evaluate_model(data, data_y, train_loader, test_loader):
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(data, data_y)

    if X_train.shape[1] == 0:
        print("Sequence length is 0. Skipping.")
        return None, None, None

    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals = 50)
    print("Best Hyperparameters:", best)

    best_model = LSTM(input_size=X_train.shape[2],
                      output_size=1,
                      num_fc_layers=best['num_fc_layers'],
                      num_lstm_node=best['num_lstm_node'],
                      num_fc_node=best['num_fc_node'],
                      dropout_rate=best['dropout_rate'],
                      num_layers=2)


    with torch.no_grad():
        y_pred = best_model(X_test)
        y_pred = y_pred.numpy()
        evaluation = evaluate_metrics(y_test, y_pred)


    return evaluation, y_pred, X_train

for i in tqdm(range(180, 200)):  # 0 ~ 100
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(features_train[i], labels_train[i])
    evaluation, y_pred, X_train = final_evaluate_model(features_train[i], labels_train[i], train_loader, test_loader)

    if evaluation is not None and y_pred is not None and X_train is not None:
        evaluation_metrics.append(evaluation)
        y_pred_list.append(y_pred)
        y_test_list.append(y_test)

    if (i + 1) % 20 == 0:
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm-exog1/y_pred_list_{i + 1}.pkl', 'wb') as f:
            pickle.dump(y_pred_list, f)
            print(f'y_pred_list_{i + 1}.pkl saved.')
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm-exog1/evaluation_metrics_{i + 1}.pkl', 'wb') as f:
            pickle.dump(evaluation_metrics, f)
            print(f'evaluation_metrics_{i + 1}.pkl saved.')
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/lstm-exog1/y_test_list_{i + 1}.pkl', 'wb') as f:
            pickle.dump(y_test_list, f)
            print(f'y_test_list_{i + 1}.pkl saved.')

mean_rmse = np.mean([evaluation['RMSE'] for evaluation in evaluation_metrics])
mean_mae = np.mean([evaluation['MAE'] for evaluation in evaluation_metrics])
mean_mape = np.mean([evaluation['MAPE'] for evaluation in evaluation_metrics])

print("Mean RMSE:", mean_rmse)
print("Mean MAE:", mean_mae)
print("Mean MAPE:", mean_mape)

"""### 4. Hyrbrid"""

def find_optimal_order(data):
    orders = [] ; seasonal_orders = []

    for i in tqdm(range(202), desc = "Fitting SARIMAX models"):
        exogenous_series = exogenous_series = np.random.binomial(1, 0.1, size = 351)

        # AIC 기준을 이용하여 적절한 SARIMAX 모형의 차수 결정
        arima_model = auto_arima(y = data[i][:351],
                                 x = exogenous_series,
                                 m = 7,
                                 seasonal = True,
                                 stepwise = True,
                                 error_action = "ignore",
                                 suppress_warnings = True,
                                 information_criterion = 'aic')

        order = arima_model.order
        seasonal_order = arima_model.seasonal_order

        orders.append(order)
        seasonal_orders.append(seasonal_order)

    return orders, seasonal_orders

optimal_orders = find_optimal_order(simulated_data_results)

orders = optimal_orders[0]
seasonal_orders = optimal_orders[1]

# parameter
def find_optimal_param(data, orders, seasonal_orders):
    all_results = []

    for i in tqdm(range(len(orders)), desc = "Fitting SARIMAX models"):
        exogenous_series = np.random.choice([0, 1], size = 365, p = [1 - 0.1, 0.1])
        sarimax_model = SARIMAX(endog = data[i],
                                exog = exogenous_series,
                                order = orders[i],
                                seasonal_order = seasonal_orders[i],
                                initialization='approximate_diffuse').fit(disp = False)

        params_pvalues = sarimax_model.pvalues # pvalue
        true_param_names = params_pvalues.index.tolist() # 전체 parameter
        significant_param_names = params_pvalues[params_pvalues < 0.05].index.tolist() # filtered parameter
        param = sarimax_model.params.loc[significant_param_names].values  # parameter coefficients

        residuals = sarimax_model.resid  # Residuals

        all_results.append((orders[i],
                            seasonal_orders[i],
                            true_param_names,
                            significant_param_names,
                            sarimax_model.params[significant_param_names].tolist(),
                            param.tolist(),
                            residuals.tolist()))
    return all_results

auto_arima_results = find_optimal_param(simulated_data_results, orders, seasonal_orders)

orders, seasonal_orders, true_param_names, all_significant_params, param, coefficients, residuals = zip(*auto_arima_results)

def extract_factors(coeff, key_pattern):
    factors = {int(re.search(r'\d+', key).group()): value for key, value in coeff.items() if key.startswith(key_pattern)}
    keys = {key: value for key, value in coeff.items() if not key.startswith(key_pattern)}
    return factors, keys

def calculate_cumulative_results(coeff, simulated_data, residuals):
    ar_factors, _ = extract_factors(coeff, 'ar.L')
    ma_factors, _ = extract_factors(coeff, 'ma.L')
    ar_s_factors, _ = extract_factors(coeff, 'ar.S')
    ma_s_factors, _ = extract_factors(coeff, 'ma.S')
    exog_factors, _ = extract_factors(coeff, 'x1')

    cumulative_results_list = []

    for i, data_point in enumerate(simulated_data):
        exogenous_series = exogenous_series = np.random.binomial(1, 0.1, size = 365) # exogenous_series 때문에 input이 다 다름

        ar_dict = {f'ar.L{j}': ar_factors[j] * simulated_data[i - j] for j in ar_factors if (i - j) >= 0}
        ma_dict = {f'ma.L{j}': ma_factors[j] * residuals[i - j] for j in ma_factors if (i - j) >= 0}
        ar_s_dict = {f'ar.S.L{j}': ar_s_factors[j] * simulated_data[i - j] for j in ar_s_factors if (i - j) >= 0}
        ma_s_dict = {f'ma.S.L{j}': ma_s_factors[j] * residuals[i - j] for j in ma_s_factors if (i - j) >= 0}

        exog_value = list(exog_factors.values())[0]
        exog_dict = {'x1': exog_value *  exogenous_series[i]}

        exog_ar_dict = {f'exog_ar.L{j}': ar_factors[j] * exogenous_series[i - j] * exog_value for j in ar_factors}
        exog_ar_s_dict = {f'exog_ar_s.L{j}': exog_value * ar_s_factors[j] * exogenous_series[i - j] for j in ar_s_factors}

        cumulative_results = {**ar_dict, **ma_dict, **ar_s_dict, **ma_s_dict, **exog_dict, **exog_ar_dict, **exog_ar_s_dict}
        cumulative_results = {key: float(value) for key, value in cumulative_results.items() if value != 0}  # Remove entries with value 0
        cumulative_results_list.append(cumulative_results)

    return cumulative_results_list

def input_transformation(simulated_data_results, param, true_param_names, all_significant_params, coefficients, residuals):
    result_list = []

    zero_array_lists = [np.zeros(len(params)).astype(int) for params in true_param_names]
    param_dict = [dict(zip(true_param_names, zero_array_list)) for true_param_names, zero_array_list in zip(true_param_names, zero_array_lists)]
    coefficients = [dict(zip(significant_params, params)) for significant_params, params in zip(all_significant_params, param)]
    result_dicts = [{key: coefficient[key] if key in coefficient else value for key, value in param.items()} for param, coefficient in zip(param_dict, coefficients)]

    for i, coeff in enumerate(result_dicts):
        cumulative_results = calculate_cumulative_results(coeff, simulated_data_results[i], residuals[i])
        result_list.append(cumulative_results)

    return result_list

input = input_transformation(simulated_data_results[:len(orders)], param, true_param_names, all_significant_params, coefficients, residuals)

input_list_fin = []

for i in tqdm(range(len(input))):
    input_list = []
    for j in range(len(input[i])):
        input_values = list(input[i][j].values())
        input_df = pd.DataFrame([input_values])
        input_list.append(input_df)

    input_dataframe = pd.concat(input_list, axis = 0, ignore_index = True)
    input_dataframe.fillna(0, inplace = True)  # NA를 전부 0으로 체우기
    input_list_fin.append(input_dataframe)

input_list_fin_scaled = []
simulated_data_results_scaled = []

for i in tqdm(range(200)):
    concatenated_data = pd.concat([pd.DataFrame(input_list_fin[i]), pd.DataFrame(simulated_data_results[i])], axis=1)

    concatenated_data.columns = concatenated_data.columns.astype(str)

    scaler = MinMaxScaler()
    concatenated_data_scaled = scaler.fit_transform(concatenated_data)

    input_list_fin_i_scaled = concatenated_data_scaled[:, :len(input_list_fin[i])]
    simulated_data_results_i_scaled = concatenated_data_scaled[:, -1]

    input_list_fin_i_scaled = np.where(np.isnan(input_list_fin_i_scaled), 0, input_list_fin_i_scaled)

    input_list_fin_scaled.append(input_list_fin_i_scaled)
    simulated_data_results_scaled.append(simulated_data_results_i_scaled)

def train_test_split(x_data, y_data , time_step = 14):
    X, y = [], []
    for i in range(len(x_data) - time_step):
        X.append(x_data[i:i+time_step])
        y.append(y_data[i+time_step])
    return X, y

# LSTM
class LSTM(nn.Module):
    def __init__(self, input_size, output_size, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate, num_layers):
        super(LSTM, self).__init__()

        self.num_fc_layers = int(num_fc_layers)
        self.num_lstm_node = int(num_lstm_node)
        self.num_fc_node = int(num_fc_node)
        self.dropout_rate = dropout_rate
        self.input_size = int(input_size)
        self.output_size = int(output_size)
        self.num_layers = int(num_layers)

        self.lstm = nn.LSTM(input_size=self.input_size,
                            hidden_size=self.num_lstm_node,
                            num_layers=self.num_layers,
                            batch_first=True)
        self.dropout = nn.Dropout(p=dropout_rate)

        self.fc_layers = nn.ModuleList([])

        if self.num_fc_layers >= 1:
            self.fc_layers.append(nn.Linear(self.num_lstm_node, self.num_fc_node))
            if self.num_fc_layers > 1:
                for _ in range(self.num_fc_layers - 1):
                    self.fc_layers.append(nn.Linear(self.num_fc_node, self.num_fc_node))

            self.output_layer = nn.Linear(self.num_fc_node, self.output_size)
        else:
            self.output_layer = nn.Linear(self.num_lstm_node, self.output_size)
        self.tanh = nn.Tanh()

    def forward(self, x):
        h_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        c_n = torch.zeros(self.num_layers, x.size(0), self.num_lstm_node).to(x.device)
        out, (h_n, c_n) = self.lstm(x, (h_n, c_n))
        out = out[:, -1, :]

        out = self.tanh(out)
        out = self.dropout(out)

        for layer in self.fc_layers:
            out = layer(out)
            out = self.tanh(out)
            out = self.dropout(out)

        out = self.output_layer(out)

        return out

def train_evaluate_lstm(learning_rate, num_fc_layers, num_lstm_node, num_fc_node, dropout_rate):
    model = LSTM(input_size = X_train.shape[2],
                 output_size = 1,
                 num_fc_layers = num_fc_layers,
                 num_lstm_node = num_lstm_node,
                 num_fc_node = num_fc_node,
                 dropout_rate = dropout_rate,
                 num_layers = 2)
    model.to(device)  # GPU

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr = learning_rate)

    num_epochs = 1000
    early_stopping_patience = 50
    best_valid_loss = float('inf')
    no_improvement = 0

    for epoch in range(num_epochs):
        model.train()
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)  # GPU
            optimizer.zero_grad()
            outputs = model(inputs)
            labels = labels.view(labels.size(0), -1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        model.eval()
        valid_loss = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                labels = labels.view(labels.size(0), -1)
                valid_loss += criterion(outputs, labels).item()
        valid_loss /= len(test_loader)

        if valid_loss < best_valid_loss:
            best_valid_loss = valid_loss
            no_improvement = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            no_improvement += 1

        if no_improvement >= early_stopping_patience:
            print(f'Early stopping after {epoch + 1} epochs with no improvement.')
            break

    return best_valid_loss


space = {
    'learning_rate': hp.uniform('learning_rate', 0.001, 0.01),
    'num_fc_layers': hp.quniform('num_fc_layers', 0, 2, 1),
    'num_lstm_node': hp.quniform('num_lstm_node', 16, 128, 16),
    'num_fc_node': hp.quniform('num_fc_node', 16, 128, 16),
    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5)
}

def objective(params):
    try:
        test_loss = train_evaluate_lstm(learning_rate = params['learning_rate'],
                                        num_fc_layers = params['num_fc_layers'],
                                        num_lstm_node = params['num_lstm_node'],
                                        num_fc_node = params['num_fc_node'],
                                        dropout_rate = params['dropout_rate'])

        return test_loss

    except Exception as e:
        print("Error occurred:", e)
        return float('inf')


evaluation_metrics = []
y_pred_list = []
y_test_list = []

def prepare_data(data, data_y):
    X, y = train_test_split(data, data_y, time_step=14)

    X_train, y_train = X[:337], y[:337]
    X_test, y_test = X[337:], y[337:]

    # To tensor
    X_train = torch.Tensor(X_train)
    X_test = torch.Tensor(X_test)

    y_train = torch.Tensor(y_train).view(-1, 1)
    y_test = torch.Tensor(y_test).view(-1, 1)

    # Reshape tensor
    X_train = X_train.permute(0, 2, 1)
    X_test = X_test.permute(0, 2, 1)

    # To data loader
    train_data = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)

    test_data = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_data, batch_size=32)

    return X_train, X_test, y_train, y_test, train_loader, test_loader

def final_evaluate_model(data, data_y, train_loader, test_loader):
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(data, data_y)

    if X_train.shape[1] == 0:
        print("Sequence length is 0. Skipping.")
        return None, None, None

    best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals = 50)
    print("Best Hyperparameters:", best)

    best_model = LSTM(input_size=X_train.shape[2],
                      output_size=1,
                      num_fc_layers=best['num_fc_layers'],
                      num_lstm_node=best['num_lstm_node'],
                      num_fc_node=best['num_fc_node'],
                      dropout_rate=best['dropout_rate'],
                      num_layers=2)


    with torch.no_grad():
        y_pred = best_model(X_test)
        y_pred = y_pred.numpy()
        evaluation = evaluate_metrics(y_test, y_pred)


    return evaluation, y_pred, X_train

for i in tqdm(range(0, 20)):  # 0 ~ 100
    X_train, X_test, y_train, y_test, train_loader, test_loader = prepare_data(input_list_fin_scaled[i], simulated_data_results_scaled[i])
    evaluation, y_pred, X_train = final_evaluate_model(input_list_fin_scaled[i], simulated_data_results_scaled[i], train_loader, test_loader)

    if evaluation is not None and y_pred is not None and X_train is not None:
        evaluation_metrics.append(evaluation)
        y_pred_list.append(y_pred)
        y_test_list.append(y_test)

    if (i + 1) % 20 == 0:
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/hybrid1/y_pred_list_{i + 1}.pkl', 'wb') as f:
            pickle.dump(y_pred_list, f)
            print(f'y_pred_list_{i + 1}.pkl saved.')
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/hybrid1/evaluation_metrics_{i + 1}.pkl', 'wb') as f:
            pickle.dump(evaluation_metrics, f)
            print(f'evaluation_metrics_{i + 1}.pkl saved.')
        with open(f'/content/drive/MyDrive/[고급시계열] 기말발표/데이터/simulated_data/보고서/hybrid1/y_test_list_{i + 1}.pkl', 'wb') as f:
            pickle.dump(y_test_list, f)
            print(f'y_test_list_{i + 1}.pkl saved.')